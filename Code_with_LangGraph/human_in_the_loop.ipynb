{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"3931b6a9","executionInfo":{"status":"ok","timestamp":1728159669421,"user_tz":-180,"elapsed":16733,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["%%capture --no-stderr\n","%pip install -U langgraph langsmith langchain-openai tavily-python"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"0828830b","executionInfo":{"status":"ok","timestamp":1728159729279,"user_tz":-180,"elapsed":285,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["import getpass\n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"bc6d3dfe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728159774933,"user_tz":-180,"elapsed":7856,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"70f9198b-7792-4e8d-a761-624b62289ce3"},"outputs":[{"name":"stdout","output_type":"stream","text":["OPENAI_API_KEY: ··········\n"]}],"source":["def _set_env(var: str):\n","    if not os.environ.get(var):\n","        os.environ[var] = getpass.getpass(f\"{var}: \")\n","\n","_set_env(\"OPENAI_API_KEY\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"0c52923c-5665-4f8c-a1ba-9799e369c49e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728159781498,"user_tz":-180,"elapsed":5083,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"8af9da67-4e57-4e59-96b2-31950ea29e19"},"outputs":[{"name":"stdout","output_type":"stream","text":["TAVILY_API_KEY: ··········\n"]}],"source":["_set_env(\"TAVILY_API_KEY\")"]},{"cell_type":"markdown","metadata":{"id":"6f1da240-ec9b-441f-9d47-44c6dc85d540"},"source":["## Human-in-the-loop\n","\n","Agents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\n","\n","LangGraph supports `human-in-the-loop` workflows in a number of ways. In this section, we will use LangGraph's `interrupt_before` functionality to always break the tool node.\n","\n","First, start from our existing code. The following is copied from Part 3."]},{"cell_type":"code","source":["!pip install langchain_community"],"metadata":{"id":"0T2Ut9C8XJia","executionInfo":{"status":"ok","timestamp":1728159996550,"user_tz":-180,"elapsed":9438,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"1b8a151c-6516-42e0-8ba6-0a492166e7cb","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain_community\n","  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.8)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting langchain<0.4.0,>=0.3.1 (from langchain_community)\n","  Downloading langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.9)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.131)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n","  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.1->langchain_community)\n","  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.1->langchain_community) (2.9.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.7)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n","Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain_community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain_community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain_community) (2.23.4)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n","Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading langchain-0.3.2-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n","Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n","Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-text-splitters, langchain, langchain_community\n","Successfully installed dataclasses-json-0.6.7 langchain-0.3.2 langchain-text-splitters-0.3.0 langchain_community-0.3.1 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 python-dotenv-1.0.1 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"EBDvZyyCXJnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"5a81608a-373a-4339-b1c6-65b73a92b983","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"error","timestamp":1728159996813,"user_tz":-180,"elapsed":266,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"be0898cb-6697-457f-fb0e-c527df732271"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'langgraph.checkpoint.sqlite'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-af5c8970862c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTypedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqlite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSqliteSaver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_messages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph.checkpoint.sqlite'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from typing import Annotated\n","from langchain_openai import ChatOpenAI\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from typing_extensions import TypedDict\n","\n","from langgraph.checkpoint.sqlite import SqliteSaver\n","from langgraph.graph import StateGraph\n","from langgraph.graph.message import add_messages\n","from langgraph.prebuilt import ToolNode, tools_condition\n","\n","memory = SqliteSaver.from_conn_string(\":memory:\")\n","\n","\n","class State(TypedDict):\n","    messages: Annotated[list, add_messages]\n","\n","graph_builder = StateGraph(State)\n","\n","tool = TavilySearchResults(max_results=2)\n","tools = [tool]\n","llm = ChatOpenAI(model=\"gpt-4o\")\n","llm_with_tools = llm.bind_tools(tools)\n","\n","def chatbot(state: State):\n","    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n","\n","graph_builder.add_node(\"chatbot\", chatbot)\n","\n","tool_node = ToolNode(tools=[tool])\n","graph_builder.add_node(\"tools\", tool_node)\n","\n","graph_builder.add_conditional_edges(\n","    \"chatbot\",\n","    tools_condition,\n",")\n","graph_builder.add_edge(\"tools\", \"chatbot\")\n","graph_builder.set_entry_point(\"chatbot\")"]},{"cell_type":"markdown","metadata":{"id":"813505b2-18c1-46e9-b891-20a34232808b"},"source":["Now, compile the graph, specifying to `interrupt_before` the `action` node."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0883e32-1a39-4ce9-ae32-bbd66708fd84"},"outputs":[],"source":["graph = graph_builder.compile(\n","    checkpointer=memory,\n","    # This is new!\n","    interrupt_before=[\"tools\"],\n","    # Note: can also interrupt __after__ actions, if desired.\n","    # interrupt_after=[\"tools\"]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9f318020-ab7e-415b-a5e2-eddec6d9f3a6","outputId":"2d858a47-fad3-491f-c550-1e64bf6e8fd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","I'm learning LangGraph. Could you do some research on it for me?\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","Tool Calls:\n","  tavily_search_results_json (call_QbncOjIgKqiyOVED2gmMbeTA)\n"," Call ID: call_QbncOjIgKqiyOVED2gmMbeTA\n","  Args:\n","    query: LangGraph programming language overview\n","  tavily_search_results_json (call_6K6AuOBkfaor6qQAyGW3V9FE)\n"," Call ID: call_6K6AuOBkfaor6qQAyGW3V9FE\n","  Args:\n","    query: LangGraph tutorials and learning resources\n"]}],"source":["user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n","config = {\"configurable\": {\"thread_id\": \"1\"}}\n","# The config is the **second positional argument** to stream() or invoke()!\n","events = graph.stream(\n","    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",")\n","for event in events:\n","    if \"messages\" in event:\n","        event[\"messages\"][-1].pretty_print()"]},{"cell_type":"markdown","metadata":{"id":"39405637-13b1-40b1-a51e-6d60bf675ff1"},"source":["Let's inspect the graph state to confirm it worked."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bb7af46-9b4f-4bb1-b8b9-e9ddf7dbc82c","outputId":"ab3a8dd1-93dc-4315-9a89-ec7ade7996bd"},"outputs":[{"data":{"text/plain":["('tools',)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["snapshot = graph.get_state(config)\n","snapshot.next"]},{"cell_type":"markdown","metadata":{"id":"89326046-2b11-4812-8b6d-8780306ec275"},"source":["**Notice** that unlike last time, the \"next\" node is set to **'action'**. We've interrupted here! Let's check the tool invocation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3facda0a-e6ad-4b28-b627-753ad8c90c15","outputId":"9e3a3182-1098-44b3-e7c0-6faa69903e41"},"outputs":[{"data":{"text/plain":["[{'name': 'tavily_search_results_json',\n","  'args': {'query': 'LangGraph programming language overview'},\n","  'id': 'call_QbncOjIgKqiyOVED2gmMbeTA'},\n"," {'name': 'tavily_search_results_json',\n","  'args': {'query': 'LangGraph tutorials and learning resources'},\n","  'id': 'call_6K6AuOBkfaor6qQAyGW3V9FE'}]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["existing_message = snapshot.values[\"messages\"][-1]\n","existing_message.tool_calls"]},{"cell_type":"markdown","metadata":{"id":"a55a4c70-7226-4be0-8562-391f72bc1f2b"},"source":["This query seems reasonable. Nothing to filter here. The simplest thing the human can do is just let the graph continue executing. Let's do that below.\n","\n","Next, continue the graph! Passing in `None` will just let the graph continue where it left off, without adding anything new to the state."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"effb95d9-b7d5-40c5-9253-253d193b23b2","outputId":"66860d23-bc77-4a99-c5c0-d4b8a6f16cf9"},"outputs":[{"name":"stdout","output_type":"stream","text":["=================================\u001b[1m Tool Message \u001b[0m=================================\n","Name: tavily_search_results_json\n","\n","[{\"url\": \"https://langchain-ai.github.io/langgraph/tutorials/\", \"content\": \"These notebooks introduce LangGraph through building various language agents and applications. Introduction to LangGraph\\u00b6 Learn the basics of LangGraph through the onboarding tutorials. Introduction to LangGraph; Use cases\\u00b6 Learn from example implementations of graphs designed for specific scenarios and that implement common design patterns ...\"}, {\"url\": \"https://github.com/LangGraph-GUI/LangGraph-learn/\", \"content\": \"Introduction. LangGraph-learn is designed to foster a collaborative learning environment for individuals interested in AI and machine learning. Our goal is to provide practical examples and tutorials that demonstrate how to use LangGraph, LangChain, and other related tools to build efficient and reusable workflows involving language models.\"}]\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Here's a summary of the information I found about LangGraph:\n","\n","### Overview of LangGraph\n","1. **LangGraph** is a library focused on building stateful, multi-actor applications using Large Language Models (LLMs). It extends the LangChain Expression Language by enabling the coordination of multiple chains (or actors) across different tasks.\n","   - **Source**: [Medium Guide on LangGraph](https://medium.com/@bhavikjikadara/langgraph-a-comprehensive-guide-for-beginners-ef17d3dd5383)\n","   - **Source**: [Introduction to LangGraph](https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141)\n","\n","### Tutorials and Learning Resources\n","1. **Official LangGraph Tutorials**: The LangGraph tutorials introduce the basics through various notebooks. These resources provide practical examples and demonstrate how to build language agents and applications using LangGraph.\n","   - **Source**: [LangGraph Tutorials](https://langchain-ai.github.io/langgraph/tutorials/)\n","\n","2. **LangGraph-Learn on GitHub**: This repository is designed to foster a collaborative learning environment for AI and machine learning enthusiasts. It offers practical examples and tutorials on using LangGraph, LangChain, and related tools to create efficient and reusable workflows involving language models.\n","   - **Source**: [LangGraph-Learn GitHub Repository](https://github.com/LangGraph-GUI/LangGraph-learn/)\n","\n","### Summary\n","LangGraph is a powerful extension of the LangChain library, aimed at creating stateful applications with multiple actors using LLMs. The learning resources available, including official tutorials and a GitHub repository, provide a solid foundation for getting started with LangGraph.\n"]}],"source":["# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n","events = graph.stream(None, config, stream_mode=\"values\")\n","for event in events:\n","    if \"messages\" in event:\n","        event[\"messages\"][-1].pretty_print()"]},{"cell_type":"markdown","metadata":{"id":"21e78a97-474f-4709-b51d-9d5e8323e14c"},"source":["Review this call's [LangSmith trace](https://smith.langchain.com/public/6a9012c0-bfa2-4fba-8dce-961d233f9512/r) to see the exact work that was done in the above call. Notice that the state is loaded in the first step so that your chatbot can continue where it left off.\n","\n","**Congrats!** You've used an `interrupt` to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since we have already added a **checkpointer**, the graph can be paused **indefinitely** and resumed at any time as if nothing had happened.\n","\n","Next, we'll explore how to further customize the bot's behavior using custom state updates.\n","\n","Below is a copy of the code you used in this section. The only difference between this and the previous parts is the addition of the `interrupt_before` argument.\n","\n","<details>\n","<summary>Full Code</summary>\n","    <pre>\n","\n","```python\n","from typing import Annotated\n","\n","from langchain_anthropic import ChatAnthropic\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from langchain_core.messages import BaseMessage\n","from typing_extensions import TypedDict\n","\n","from langgraph.checkpoint.sqlite import SqliteSaver\n","from langgraph.graph import StateGraph\n","from langgraph.graph.message import add_messages\n","from langgraph.prebuilt import ToolNode\n","\n","\n","class State(TypedDict):\n","    messages: Annotated[list, add_messages]\n","\n","\n","graph_builder = StateGraph(State)\n","\n","\n","tool = TavilySearchResults(max_results=2)\n","tools = [tool]\n","llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n","llm_with_tools = llm.bind_tools(tools)\n","\n","\n","def chatbot(state: State):\n","    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n","\n","\n","graph_builder.add_node(\"chatbot\", chatbot)\n","\n","tool_node = ToolNode(tools=[tool])\n","graph_builder.add_node(\"tools\", tool_node)\n","\n","graph_builder.add_conditional_edges(\n","    \"chatbot\",\n","    tools_condition,\n",")\n","graph_builder.add_edge(\"tools\", \"chatbot\")\n","graph_builder.set_entry_point(\"chatbot\")\n","\n","memory = SqliteSaver.from_conn_string(\":memory:\")\n","graph = graph_builder.compile(\n","    checkpointer=memory,\n","    # This is new!\n","    interrupt_before=[\"tools\"],\n","    # Note: can also interrupt __after__ actions, if desired.\n","    # interrupt_after=[\"tools\"]\n",")\n","```\n","</pre>\n","</details>"]}]}