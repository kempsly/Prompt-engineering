{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"919fe33c-0149-4f7d-b200-544a18986c9a"},"source":["# Self-RAG\n","\n","Self-RAG is a strategy for RAG that incorporates self-reflection / self-grading on retrieved documents and generations.\n","\n","In the [paper](https://arxiv.org/abs/2310.11511), a few decisions are made:\n","\n","1. Should I retrieve from retriever, `R` -\n","\n","* Input: `x (question)` OR `x (question)`, `y (generation)`\n","* Decides when to retrieve `D` chunks with `R`\n","* Output: `yes, no, continue`\n","\n","2. Are the retrieved passages `D` relevant to the question `x` -\n","\n","* Input: (`x (question)`, `d (chunk)`) for `d` in `D`\n","* `d` provides useful information to solve `x`\n","* Output: `relevant, irrelevant`\n","\n","3. Are the LLM generation from each chunk in `D` is relevant to the chunk (hallucinations, etc)  -\n","\n","* Input: `x (question)`, `d (chunk)`,  `y (generation)` for `d` in `D`\n","* All of the verification-worthy statements in `y (generation)` are supported by `d`\n","* Output: `{fully supported, partially supported, no support`\n","\n","4. The LLM generation from each chunk in `D` is a useful response to `x (question)` -\n","\n","* Input: `x (question)`, `y (generation)` for `d` in `D`\n","* `y (generation)` is a useful response to `x (question)`.\n","* Output: `{5, 4, 3, 2, 1}`\n","\n","We will implement some of these ideas from scratch using [LangGraph](https://langchain-ai.github.io/langgraph/).\n","\n","![Screenshot 2024-04-01 at 12.41.50 PM.png](attachment:15cba0ab-a549-4909-8373-fb761e384eff.png)"]},{"cell_type":"markdown","metadata":{"id":"72f3ee57-68ab-4040-bd36-4014e2a23d96"},"source":["# Environment"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"a384cc48-0425-4e8f-aafc-cfb8e56025c9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728167054634,"user_tz":-180,"elapsed":36969,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"5d00e642-6c72-478d-deeb-593455e3093f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain_community\n","  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n","Collecting tiktoken\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n","Collecting langchainhub\n","  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n","Collecting chromadb\n","  Downloading chromadb-0.5.11-py3-none-any.whl.metadata (6.8 kB)\n","Collecting langchain\n","  Downloading langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting langgraph\n","  Downloading langgraph-0.2.34-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.8)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting langchain-core<0.4.0,>=0.3.6 (from langchain_community)\n","  Downloading langchain_core-0.3.9-py3-none-any.whl.metadata (6.3 kB)\n","Collecting langsmith<0.2.0,>=0.1.125 (from langchain_community)\n","  Downloading langsmith-0.1.131-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n","  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain_community)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n","Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n","  Downloading openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.1)\n","Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n","  Downloading types_requests-2.32.0.20240914-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n","Collecting chroma-hnswlib==0.7.6 (from chromadb)\n","  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n","Collecting fastapi>=0.95.2 (from chromadb)\n","  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n","Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n","Collecting posthog>=2.4.0 (from chromadb)\n","  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n","Collecting onnxruntime>=1.14.1 (from chromadb)\n","  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n","  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n","Collecting pypika>=0.48.9 (from chromadb)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.5)\n","Collecting overrides>=7.3.1 (from chromadb)\n","  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n","Collecting bcrypt>=4.0.1 (from chromadb)\n","  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.5)\n","Collecting kubernetes>=28.1.0 (from chromadb)\n","  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting mmh3>=4.0.1 (from chromadb)\n","  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n","Collecting orjson>=3.9.12 (from chromadb)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx>=0.27.0 (from chromadb)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.8.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n","  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting langgraph-checkpoint<3.0.0,>=2.0.0 (from langgraph)\n","  Downloading langgraph_checkpoint-2.0.0-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.13.1)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting starlette<0.39.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n","  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n","Collecting httpcore==1.* (from httpx>=0.27.0->chromadb)\n","  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->chromadb)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n","Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n","  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.6->langchain_community)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph)\n","  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n","Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain_community)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n","Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n","Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.4.0)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n","Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n","Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (71.0.4)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n","  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.23.4)\n","Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.24.7)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.2)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain_community)\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n","Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_openai-0.2.2-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n","Downloading chromadb-0.5.11-py3-none-any.whl (603 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m604.0/604.0 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain-0.3.2-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph-0.2.34-py3-none-any.whl (107 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.9-py3-none-any.whl (401 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n","Downloading langgraph_checkpoint-2.0.0-py3-none-any.whl (22 kB)\n","Downloading langsmith-0.1.131-py3-none-any.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.51.0-py3-none-any.whl (383 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n","Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n","Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n","Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n","Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n","Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n","Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading types_requests-2.32.0.20240914-py3-none-any.whl (15 kB)\n","Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading starlette-0.38.6-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Building wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=9a12ccff24d549133aa27449fe352c0ea5a2dc39ca1fa2b5a170dbf9917288f3\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built pypika\n","Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, types-requests, tenacity, python-dotenv, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, msgpack, mmh3, marshmallow, jsonpointer, jiter, humanfriendly, httptools, h11, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, requests-toolbelt, posthog, opentelemetry-exporter-otlp-proto-common, langchainhub, jsonpatch, httpcore, coloredlogs, pydantic-settings, opentelemetry-instrumentation, onnxruntime, kubernetes, httpx, fastapi, dataclasses-json, opentelemetry-instrumentation-asgi, openai, langsmith, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, chromadb, langgraph, langchain, langchain_community\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","  Attempting uninstall: msgpack\n","    Found existing installation: msgpack 1.0.8\n","    Uninstalling msgpack-1.0.8:\n","      Successfully uninstalled msgpack-1.0.8\n","Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 chroma-hnswlib-0.7.6 chromadb-0.5.11 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.9 fastapi-0.115.0 h11-0.14.0 httpcore-1.0.6 httptools-0.6.1 httpx-0.27.2 humanfriendly-10.0 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-31.0.0 langchain-0.3.2 langchain-core-0.3.9 langchain-openai-0.2.2 langchain-text-splitters-0.3.0 langchain_community-0.3.1 langchainhub-0.1.21 langgraph-0.2.34 langgraph-checkpoint-2.0.0 langsmith-0.1.131 marshmallow-3.22.0 mmh3-5.0.1 monotonic-1.6 msgpack-1.1.0 mypy-extensions-1.0.0 onnxruntime-1.19.2 openai-1.51.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-util-http-0.48b0 orjson-3.10.7 overrides-7.7.0 posthog-3.7.0 pydantic-settings-2.5.2 pypika-0.48.9 python-dotenv-1.0.1 requests-toolbelt-1.0.0 starlette-0.38.6 tenacity-8.5.0 tiktoken-0.8.0 types-requests-2.32.0.20240914 typing-inspect-0.9.0 uvicorn-0.31.0 uvloop-0.20.0 watchfiles-0.24.0 websockets-13.1\n"]}],"source":["%pip install -U langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph"]},{"cell_type":"markdown","metadata":{"id":"15569b93-3c68-4aac-838c-37112d33987a"},"source":["### LLMs"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"f18b63c7-d0d3-41c1-ae6b-5a0f1b8ccf0f","executionInfo":{"status":"ok","timestamp":1728167095348,"user_tz":-180,"elapsed":810,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["# import os\n","\n","# os.environ[\"OPENAI_API_KEY\"] = \"<your-api-key>\""]},{"cell_type":"code","source":["import getpass\n","import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J808o3y8yNU_","executionInfo":{"status":"ok","timestamp":1728167089361,"user_tz":-180,"elapsed":8251,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"a84107b5-b44b-4c2e-86c5-940ca9c3a151"},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":["··········\n"]}]},{"cell_type":"markdown","metadata":{"id":"532d91fb-381e-4e11-b3b1-254321351773"},"source":["### Tracing\n","\n","Optionally, use [LangSmith](https://docs.smith.langchain.com/) for tracing (shown at bottom)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ccc3dae5-1df6-48ca-af8a-50f0e6128876","executionInfo":{"status":"ok","timestamp":1728167122778,"user_tz":-180,"elapsed":474,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n","os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n","# os.environ[\"LANGCHAIN_API_KEY\"] = \"<your-api-key>\""]},{"cell_type":"code","source":["import getpass\n","import os\n","\n","os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VirvOBcoyVw1","executionInfo":{"status":"ok","timestamp":1728167184849,"user_tz":-180,"elapsed":58542,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"8d100fc2-ce4a-414e-9c18-273373e4b177"},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":["··········\n"]}]},{"cell_type":"markdown","metadata":{"id":"c27bebdc-be71-4130-ab9d-42f09f87658b"},"source":["## Retriever\n","\n","Let's index 3 blog posts."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"565a6d44-2c9f-4fff-b1ec-eea05df9350d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728167227730,"user_tz":-180,"elapsed":18929,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"da18099e-433d-49fd-d667-2e801fc291ea"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"]}],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.document_loaders import WebBaseLoader\n","from langchain_community.vectorstores import Chroma\n","from langchain_openai import OpenAIEmbeddings\n","\n","urls = [\n","    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n","    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n","    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n","]\n","\n","docs = [WebBaseLoader(url).load() for url in urls]\n","docs_list = [item for sublist in docs for item in sublist]\n","\n","text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n","    chunk_size=250, chunk_overlap=0\n",")\n","doc_splits = text_splitter.split_documents(docs_list)\n","\n","# Add to vectorDB\n","vectorstore = Chroma.from_documents(\n","    documents=doc_splits,\n","    collection_name=\"rag-chroma\",\n","    embedding=OpenAIEmbeddings(),\n",")\n","retriever = vectorstore.as_retriever()"]},{"cell_type":"markdown","metadata":{"id":"29c12f74-53e2-43cc-896f-875d1c5d9d93"},"source":["## LLMs"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"1fafad21-60cc-483e-92a3-6a7edb1838e3","outputId":"59653222-56c3-4e34-d42b-7dd2f88d9df0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728167244089,"user_tz":-180,"elapsed":1746,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n","\n","For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n","with: `from pydantic import BaseModel`\n","or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n","\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]},{"output_type":"stream","name":"stdout","text":["binary_score='yes'\n"]}],"source":["### Retrieval Grader\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain_openai import ChatOpenAI\n","\n","# Data model\n","class GradeDocuments(BaseModel):\n","    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n","\n","    binary_score: str = Field(\n","        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n","    )\n","\n","# LLM with function call\n","llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n","structured_llm_grader = llm.with_structured_output(GradeDocuments)\n","\n","# Prompt\n","system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n","    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n","    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n","    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n","\n","grade_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system),\n","        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n","    ]\n",")\n","\n","retrieval_grader = grade_prompt | structured_llm_grader\n","question = \"agent memory\"\n","docs = retriever.invoke(question)\n","doc_txt = docs[1].page_content\n","print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"dcd77cc1-4587-40ec-b633-5364eab9e1ec","outputId":"99375a2d-2e3b-4ed4-8ab2-bee16e04f04c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728167383779,"user_tz":-180,"elapsed":2087,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Agent memory in LLM-powered autonomous agents involves both short-term and long-term memory components. Short-term memory is utilized through in-context learning, while long-term memory allows the agent to retain and recall information over extended periods, often using an external database or vector store. This memory system enables agents to behave based on past experiences and interact effectively with other agents.\n"]}],"source":["### Generate\n","\n","from langchain import hub\n","from langchain_core.output_parsers import StrOutputParser\n","\n","# Prompt\n","prompt = hub.pull(\"rlm/rag-prompt\")\n","\n","# LLM\n","llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n","\n","# Post-processing\n","def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","\n","# Chain\n","rag_chain = prompt | llm | StrOutputParser()\n","\n","# Run\n","generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n","print(generation)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"e78931ec-940c-46ad-a0b2-f43f953f1fd7","outputId":"0c7c902a-501c-4787-a6a9-acbb366d69de","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728168637946,"user_tz":-180,"elapsed":1714,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["GradeHallucinations(binary_score='yes')"]},"metadata":{},"execution_count":9}],"source":["### Hallucination Grader\n","\n","# Data model\n","class GradeHallucinations(BaseModel):\n","    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n","\n","    binary_score: str = Field(\n","        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n","    )\n","\n","\n","# LLM with function call\n","llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n","structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n","\n","# Prompt\n","system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n","     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n","hallucination_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system),\n","        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n","    ]\n",")\n","\n","hallucination_grader = hallucination_prompt | structured_llm_grader\n","hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bd62276f-bf26-40d0-8cff-e07b10e00321","outputId":"5aee70b7-1529-4710-f664-b2ad0dd122aa"},"outputs":[{"data":{"text/plain":["GradeAnswer(binary_score='no')"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["### Answer Grader\n","\n","# Data model\n","class GradeAnswer(BaseModel):\n","    \"\"\"Binary score to assess answer addresses question.\"\"\"\n","\n","    binary_score: str = Field(\n","        description=\"Answer addresses the question, 'yes' or 'no'\"\n","    )\n","\n","# LLM with function call\n","llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n","structured_llm_grader = llm.with_structured_output(GradeAnswer)\n","\n","# Prompt\n","system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n\n","     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n","answer_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system),\n","        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n","    ]\n",")\n","\n","answer_grader = answer_prompt | structured_llm_grader\n","answer_grader.invoke({\"question\": question, \"generation\": generation})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6f4c70e-1660-4149-82c0-837f19fc9fb5","outputId":"b8d161e1-04cb-41b9-dd0e-97df3eb444af"},"outputs":[{"data":{"text/plain":["'What is the role and function of agent memory in artificial intelligence systems?'"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["### Question Re-writer\n","\n","# LLM\n","llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n","\n","# Prompt\n","system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n\n","     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n","re_write_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system),\n","        (\n","            \"human\",\n","            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n","        ),\n","    ]\n",")\n","\n","question_rewriter = re_write_prompt | llm | StrOutputParser()\n","question_rewriter.invoke({\"question\": question})"]},{"cell_type":"markdown","metadata":{"id":"276001c5-c079-4e5b-9f42-81a06704d200"},"source":["# Graph\n","\n","Capture the flow in as a graph.\n","\n","## Graph state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f1617e9e-66a8-4c1a-a1fe-cc936284c085"},"outputs":[],"source":["from typing import List\n","from typing_extensions import TypedDict\n","\n","\n","class GraphState(TypedDict):\n","    \"\"\"\n","    Represents the state of our graph.\n","\n","    Attributes:\n","        question: question\n","        generation: LLM generation\n","        documents: list of documents\n","    \"\"\"\n","\n","    question: str\n","    generation: str\n","    documents: List[str]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"add509d8-6682-4127-8d95-13dd37d79702"},"outputs":[],"source":["### Nodes\n","\n","def retrieve(state):\n","    \"\"\"\n","    Retrieve documents\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): New key added to state, documents, that contains retrieved documents\n","    \"\"\"\n","    print(\"---RETRIEVE---\")\n","    question = state[\"question\"]\n","\n","    # Retrieval\n","    documents = retriever.invoke(question)\n","    return {\"documents\": documents, \"question\": question}\n","\n","\n","def generate(state):\n","    \"\"\"\n","    Generate answer\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): New key added to state, generation, that contains LLM generation\n","    \"\"\"\n","    print(\"---GENERATE---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # RAG generation\n","    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n","    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n","\n","\n","def grade_documents(state):\n","    \"\"\"\n","    Determines whether the retrieved documents are relevant to the question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Updates documents key with only filtered relevant documents\n","    \"\"\"\n","\n","    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Score each doc\n","    filtered_docs = []\n","    for d in documents:\n","        score = retrieval_grader.invoke(\n","            {\"question\": question, \"document\": d.page_content}\n","        )\n","        grade = score.binary_score\n","        if grade == \"yes\":\n","            print(\"---GRADE: DOCUMENT RELEVANT---\")\n","            filtered_docs.append(d)\n","        else:\n","            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n","            continue\n","    return {\"documents\": filtered_docs, \"question\": question}\n","\n","\n","def transform_query(state):\n","    \"\"\"\n","    Transform the query to produce a better question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Updates question key with a re-phrased question\n","    \"\"\"\n","\n","    print(\"---TRANSFORM QUERY---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Re-write question\n","    better_question = question_rewriter.invoke({\"question\": question})\n","    return {\"documents\": documents, \"question\": better_question}\n","\n","\n","### Edges\n","\n","\n","def decide_to_generate(state):\n","    \"\"\"\n","    Determines whether to generate an answer, or re-generate a question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        str: Binary decision for next node to call\n","    \"\"\"\n","\n","    print(\"---ASSESS GRADED DOCUMENTS---\")\n","    state[\"question\"]\n","    filtered_documents = state[\"documents\"]\n","\n","    if not filtered_documents:\n","        # All documents have been filtered check_relevance\n","        # We will re-generate a new query\n","        print(\n","            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n","        )\n","        return \"transform_query\"\n","    else:\n","        # We have relevant documents, so generate answer\n","        print(\"---DECISION: GENERATE---\")\n","        return \"generate\"\n","\n","\n","def grade_generation_v_documents_and_question(state):\n","    \"\"\"\n","    Determines whether the generation is grounded in the document and answers question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        str: Decision for next node to call\n","    \"\"\"\n","\n","    print(\"---CHECK HALLUCINATIONS---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","    generation = state[\"generation\"]\n","\n","    score = hallucination_grader.invoke(\n","        {\"documents\": documents, \"generation\": generation}\n","    )\n","    grade = score.binary_score\n","\n","    # Check hallucination\n","    if grade == \"yes\":\n","        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n","        # Check question-answering\n","        print(\"---GRADE GENERATION vs QUESTION---\")\n","        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n","        grade = score.binary_score\n","        if grade == \"yes\":\n","            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n","            return \"useful\"\n","        else:\n","            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n","            return \"not useful\"\n","    else:\n","        print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n","        return \"not supported\""]},{"cell_type":"markdown","metadata":{"id":"61cd5797-1782-4d78-a277-8196d13f3e1b"},"source":["## Build Graph\n","\n","The just follows the flow we outlined in the figure above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0e09ca9f-e36d-4ef4-a0d5-79fdbada9fe0"},"outputs":[],"source":["from langgraph.graph import END, StateGraph\n","\n","workflow = StateGraph(GraphState)\n","\n","# Define the nodes\n","workflow.add_node(\"retrieve\", retrieve)  # retrieve\n","workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n","workflow.add_node(\"generate\", generate)  # generatae\n","workflow.add_node(\"transform_query\", transform_query)  # transform_query\n","\n","# Build graph\n","workflow.set_entry_point(\"retrieve\")\n","workflow.add_edge(\"retrieve\", \"grade_documents\")\n","workflow.add_conditional_edges(\n","    \"grade_documents\",\n","    decide_to_generate,\n","    {\n","        \"transform_query\": \"transform_query\",\n","        \"generate\": \"generate\",\n","    },\n",")\n","workflow.add_edge(\"transform_query\", \"retrieve\")\n","workflow.add_conditional_edges(\n","    \"generate\",\n","    grade_generation_v_documents_and_question,\n","    {\n","        \"not supported\": \"generate\",\n","        \"useful\": END,\n","        \"not useful\": \"transform_query\",\n","    },\n",")\n","\n","# Compile\n","app = workflow.compile()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fb69dbb9-91ee-4868-8c3c-93af3cd885be","outputId":"f419ac70-a8dc-4e50-91a9-1f89dec0063c"},"outputs":[{"name":"stdout","output_type":"stream","text":["---RETRIEVE---\n","\"Node 'retrieve':\"\n","'\\n---\\n'\n","---CHECK DOCUMENT RELEVANCE TO QUESTION---\n","---GRADE: DOCUMENT NOT RELEVANT---\n","---GRADE: DOCUMENT NOT RELEVANT---\n","---GRADE: DOCUMENT RELEVANT---\n","---GRADE: DOCUMENT RELEVANT---\n","---ASSESS GRADED DOCUMENTS---\n","---DECISION: GENERATE---\n","\"Node 'grade_documents':\"\n","'\\n---\\n'\n","---GENERATE---\n","---CHECK HALLUCINATIONS---\n","---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n","---GRADE GENERATION vs QUESTION---\n","---DECISION: GENERATION ADDRESSES QUESTION---\n","\"Node 'generate':\"\n","'\\n---\\n'\n","('Short-term memory in an agent involves in-context learning, where the model '\n"," 'uses prompt engineering to learn and adapt quickly. Long-term memory allows '\n"," 'the agent to retain and recall extensive information over extended periods '\n"," 'by leveraging an external vector store and fast retrieval mechanisms.')\n"]}],"source":["from pprint import pprint\n","\n","# Run\n","inputs = {\"question\": \"Explain how the different types of agent memory work?\"}\n","for output in app.stream(inputs):\n","    for key, value in output.items():\n","        # Node\n","        pprint(f\"Node '{key}':\")\n","        # Optional: print full state at each node\n","        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n","    pprint(\"\\n---\\n\")\n","\n","# Final generation\n","pprint(value[\"generation\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4138bc51-8c84-4b8a-8d24-f7f470721f6f","outputId":"8fa23975-dfab-452a-89ce-c52332b41384"},"outputs":[{"name":"stdout","output_type":"stream","text":["---RETRIEVE---\n","\"Node 'retrieve':\"\n","'\\n---\\n'\n","---CHECK DOCUMENT RELEVANCE TO QUESTION---\n","---GRADE: DOCUMENT RELEVANT---\n","---GRADE: DOCUMENT NOT RELEVANT---\n","---GRADE: DOCUMENT RELEVANT---\n","---GRADE: DOCUMENT RELEVANT---\n","---ASSESS GRADED DOCUMENTS---\n","---DECISION: GENERATE---\n","\"Node 'grade_documents':\"\n","'\\n---\\n'\n","---GENERATE---\n","---CHECK HALLUCINATIONS---\n","---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n","---GRADE GENERATION vs QUESTION---\n","---DECISION: GENERATION ADDRESSES QUESTION---\n","\"Node 'generate':\"\n","'\\n---\\n'\n","('Chain of thought prompting involves providing a language model with a few '\n"," 'demonstrations that include high-quality reasoning chains. These '\n"," 'demonstrations can be manually written or model-generated. This method helps '\n"," 'the model to generate more accurate and coherent responses by following the '\n"," 'provided reasoning patterns.')\n"]}],"source":["inputs = {\"question\": \"Explain how chain of thought prompting works?\"}\n","for output in app.stream(inputs):\n","    for key, value in output.items():\n","        # Node\n","        pprint(f\"Node '{key}':\")\n","        # Optional: print full state at each node\n","        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n","    pprint(\"\\n---\\n\")\n","\n","# Final generation\n","pprint(value[\"generation\"])"]}]}