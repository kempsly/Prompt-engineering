{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"wn5LUrFqVu4b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727725247482,"user_tz":-180,"elapsed":17740,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"50f50c6e-d5a1-4197-ec65-fa040155829b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n","Collecting langchain_openai\n","  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting langchain-core<0.4.0,>=0.3.6 (from langchain)\n","  Downloading langchain_core-0.3.7-py3-none-any.whl.metadata (6.3 kB)\n","Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n","  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.129-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting openai<2.0.0,>=1.40.0 (from langchain_openai)\n","  Downloading openai-1.50.2-py3-none-any.whl.metadata (24 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain_openai)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.6->langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (4.12.2)\n","Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.7.0)\n","Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain)\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n","Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_openai-0.2.1-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.7-py3-none-any.whl (400 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.129-py3-none-any.whl (292 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.50.2-py3-none-any.whl (382 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.0/383.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, jiter, h11, tiktoken, jsonpatch, httpcore, httpx, openai, langsmith, langchain-core, langchain-text-splitters, langchain_openai, langchain\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.1 langchain-core-0.3.7 langchain-text-splitters-0.3.0 langchain_openai-0.2.1 langsmith-0.1.129 openai-1.50.2 orjson-3.10.7 tenacity-8.5.0 tiktoken-0.7.0\n"]}],"source":["%pip install langchain langchain_openai --upgrade"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"yHiKw5HpVu4e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727725264902,"user_tz":-180,"elapsed":17015,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"4c211c00-9355-49b9-b99a-5c4d8b442bc8"},"outputs":[{"name":"stdout","output_type":"stream","text":["··········\n"]}],"source":["import getpass\n","import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"]},{"cell_type":"markdown","metadata":{"id":"oHOhWtsaVu4e"},"source":["Oftentimes you may want to experiment with, or even expose to the end user, multiple different ways of doing things. In order to make this experience as easy as possible, we have defined two methods.\n","\n","First, a `configurable_fields` method. This lets you configure particular fields of a runnable.\n","\n","Second, a `configurable_alternatives` method. With this method, you can list out alternatives for any particular runnable that can be set during runtime."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xkGckwGGVu4f","executionInfo":{"status":"ok","timestamp":1727725396206,"user_tz":-180,"elapsed":2239,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["from langchain_core.prompts import PromptTemplate\n","from langchain_core.runnables import ConfigurableField\n","from langchain_openai.chat_models import ChatOpenAI\n","\n","model = ChatOpenAI(temperature=0).configurable_fields(\n","    temperature=ConfigurableField(\n","        id=\"llm_temperature\",\n","        name=\"LLM Temperature\",\n","        description=\"The temperature of the LLM\",\n","    )\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"iV5y9I1ZVu4g","outputId":"f6700e78-de5e-4f51-d328-7fc8cd8d224d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727725585918,"user_tz":-180,"elapsed":887,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='27', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 11, 'total_tokens': 12, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8d6f2000-daad-425f-9fec-592beaf5b89f-0', usage_metadata={'input_tokens': 11, 'output_tokens': 1, 'total_tokens': 12})"]},"metadata":{},"execution_count":4}],"source":["model.invoke(\"pick a random number\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"L4lgYQ99Vu4g","outputId":"f3eea52d-08f1-4ab4-ac44-733f2df39ca3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727725742099,"user_tz":-180,"elapsed":838,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='27', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 11, 'total_tokens': 12, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-785c596a-7def-40ca-8789-1164bbbce721-0', usage_metadata={'input_tokens': 11, 'output_tokens': 1, 'total_tokens': 12})"]},"metadata":{},"execution_count":5}],"source":["model.with_config(configurable={\"llm_temperature\": 0.9}).invoke(\"pick a random number\")"]},{"cell_type":"markdown","metadata":{"id":"TilTEuByVu4g"},"source":["## Configuring Prompts"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"uPlXKENRVu4h","executionInfo":{"status":"ok","timestamp":1727725815659,"user_tz":-180,"elapsed":390,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["llm = ChatOpenAI(temperature=0)\n","prompt = PromptTemplate.from_template(\n","    \"Tell me a joke about {topic}\"\n",").configurable_alternatives(\n","    # This gives this field an id\n","    # When configuring the end runnable, we can then use this id to configure this field\n","    ConfigurableField(id=\"prompt\"),\n","    # This sets a default_key.\n","    # If we specify this key, the default LLM (ChatAnthropic initialized above) will be used\n","    default_key=\"joke\",\n","    # This adds a new option, with name `poem`\n","    poem=PromptTemplate.from_template(\"Write a short poem about {topic}\"),\n","    # You can add more configuration options here\n",")\n","chain = prompt | llm"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"PSBN76GtVu4h","outputId":"dfdc4b39-aaa3-49ee-c79b-7d39d0f42709","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727725858589,"user_tz":-180,"elapsed":884,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"Why did the bear break up with his girlfriend?\\nBecause he couldn't bear the relationship anymore!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 13, 'total_tokens': 32, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f45c6bff-2dcf-48fd-88b9-1851b11b7777-0', usage_metadata={'input_tokens': 13, 'output_tokens': 19, 'total_tokens': 32})"]},"metadata":{},"execution_count":7}],"source":["# By default it will write a joke\n","chain.invoke({\"topic\": \"bears\"})"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"4ehcL7VHVu4h","outputId":"adc8eaaf-7cbd-4062-d1b7-f02ff2217e08","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727725873315,"user_tz":-180,"elapsed":3269,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"In the forest deep and wild,\\nWhere the trees stand tall and proud,\\nThere roams a creature fierce and mild,\\nThe mighty bear, so strong and loud.\\n\\nWith fur as dark as midnight's cloak,\\nAnd eyes that gleam with ancient wisdom,\\nHe moves with grace, his presence spoke,\\nIn the silence of the woodland kingdom.\\n\\nHe hunts for fish in rushing streams,\\nAnd berries ripe on bushes low,\\nHis roar echoes through the moonlit beams,\\nA reminder of the wild's untamed flow.\\n\\nBut do not fear this noble beast,\\nFor he is part of nature's grand design,\\nA symbol of strength and peace,\\nIn the wilderness, where he reigns divine.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 137, 'prompt_tokens': 13, 'total_tokens': 150, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cedc2873-1a3e-46cf-908f-256bb84d40a2-0', usage_metadata={'input_tokens': 13, 'output_tokens': 137, 'total_tokens': 150})"]},"metadata":{},"execution_count":8}],"source":["# We can configure it write a poem\n","chain.with_config(configurable={\"prompt\": \"poem\"}).invoke({\"topic\": \"bears\"})"]},{"cell_type":"markdown","metadata":{"id":"v-4BFRa5Vu4h"},"source":["## Saving Configurations"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"qKyx_gp3Vu4i","executionInfo":{"status":"ok","timestamp":1727725946165,"user_tz":-180,"elapsed":356,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["openai_joke = chain.with_config(configurable={\"llm\": \"openai\"})"]},{"cell_type":"code","source":["openai_joke"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2LMJSZ9fcGi","executionInfo":{"status":"ok","timestamp":1727725955064,"user_tz":-180,"elapsed":530,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"fef06387-8f7f-48bb-f955-39a2023a447f"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RunnableBinding(bound=RunnableConfigurableAlternatives(default=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Tell me a joke about {topic}'), which=ConfigurableField(id='prompt', name=None, description=None, annotation=None, is_shared=False), alternatives={'poem': PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Write a short poem about {topic}')}, default_key='joke', prefix_keys=False)\n","| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7a63b425e560>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7a63b4290a30>, root_client=<openai.OpenAI object at 0x7a63b425eb60>, root_async_client=<openai.AsyncOpenAI object at 0x7a63b425e200>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={}, config={'configurable': {'llm': 'openai'}}, config_factories=[])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":[],"metadata":{"id":"3DA8GJYBfeOj"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}