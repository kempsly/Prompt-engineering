{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"kUVB4ZQnYO8H","outputId":"dd190708-1e5c-4f6b-f657-a1d45786cf60","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727727432873,"user_tz":-180,"elapsed":15952,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.0/383.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["%pip install langchain langchain_openai wikipedia langchain-community --upgrade --quiet"]},{"cell_type":"markdown","metadata":{"id":"BOIo7PWjYO8I"},"source":["Tools are interfaces that an agent, chain, or LLM can use to interact with the world. They combine a few things:\n","\n","- The name of the tool\n","- A description of what the tool is\n","- JSON schema of what the inputs to the tool are\n","- The function to call\n","- Whether the result of a tool should be returned directly to the user\n","\n","It is useful to have all this information because this information can be used to build action-taking systems! The name, description, and JSON schema can be used to prompt the LLM so it knows how to specify what action to take, and then the function to call is equivalent to taking that action."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Z-lUDHEFYO8I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727727440941,"user_tz":-180,"elapsed":4089,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"17d7eb0f-53fb-4840-fbe7-9450fbe8df69"},"outputs":[{"name":"stdout","output_type":"stream","text":["··········\n"]}],"source":["import getpass\n","import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cAs9uCNLYO8J","outputId":"dd189d4d-c979-4cbe-d13a-3f32cf943283","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727727449912,"user_tz":-180,"elapsed":3031,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["wikipedia\n","A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n","{'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n","Will this automatically return the output to the user? This value is a boolean: False\n"]}],"source":["# 1. Standard Tools\n","from langchain_community.tools import WikipediaQueryRun\n","from langchain_community.utilities import WikipediaAPIWrapper\n","\n","api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=1000)\n","tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n","\n","print(tool.name)\n","print(tool.description)\n","print(tool.args)\n","\n","# We can see if the tool should return directly to the user\n","print(\"Will this automatically return the output to the user? This value is a boolean:\", tool.return_direct)"]},{"cell_type":"markdown","metadata":{"id":"SGyeIdqCYO8J"},"source":["## How to Call The Tool Without An Agent:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"aJudxPNuYO8J","outputId":"aae23af7-4f4f-4ef5-f000-b69ee094275e","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1727727489638,"user_tz":-180,"elapsed":1270,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Page: Digital marketing\\nSummary: Digital marketing is the component of marketing that uses the Internet and online-based digital technologies such as desktop computers, mobile phones, and other digital media and platforms to promote products and services. It has significantly transformed the way brands and businesses utilize technology for marketing since the 1990s and 2000s. As digital platforms became increasingly incorporated into marketing plans and everyday life, and as people increasingly used digital devices instead of visiting physical shops, digital marketing campaigns have become prevalent, employing combinations of search engine optimization (SEO), search engine marketing (SEM), content marketing, influencer marketing, content automation, campaign marketing, data-driven marketing, e-commerce marketing, social media marketing, social media optimization, e-mail direct marketing, display advertising, e-books, and optical disks and games have become commonplace. Digital marketin'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["tool.invoke(\"What is Digital Marketing?\")"]},{"cell_type":"markdown","metadata":{"id":"b950Gr8iYO8J"},"source":["# 2. Creating Custom Tools\n","When constructing your own agent, you will need to provide it with a list of Tools that it can use. Besides the actual function that is called, the Tool consists of several components:\n","\n","- `name (str)`, is required and must be unique within a set of tools provided to an agent\n","- `description (str)`, is optional but recommended, as it is used by an agent to determine tool use\n","- `args_schema (Pydantic BaseModel)`, is optional but recommended, can be used to provide more information (e.g., few-shot examples) or validation for expected parameters."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"PwJlgvIDYO8J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727727535317,"user_tz":-180,"elapsed":684,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}},"outputId":"fac2c57c-be75-411e-9e99-e911070075e1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n","\n","For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n","with: `from pydantic import BaseModel`\n","or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n","\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}],"source":["# Import things that are needed generically\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain.tools import BaseTool, StructuredTool, tool"]},{"cell_type":"markdown","metadata":{"id":"CNF4sAPUYO8J"},"source":["## `@tool decorator`\n","\n","This `@tool` decorator is the simplest way to define a custom tool. The decorator uses the function name as the tool name by default, but this can be overridden by passing a string as the first argument. Additionally, the decorator will use the function’s docstring as the tool’s description - so a docstring MUST be provided."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"IalK5kusYO8J","outputId":"82946cd9-19ab-4f15-cc44-54674a1cdd87","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727727587275,"user_tz":-180,"elapsed":646,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["search\n","Look up things online.\n","{'query': {'title': 'Query', 'type': 'string'}}\n"]}],"source":["@tool\n","def search(query: str) -> str:\n","    \"\"\"Look up things online.\"\"\"\n","    return \"LangChain\"\n","\n","print(search.name)\n","print(search.description)\n","print(search.args)"]},{"cell_type":"markdown","metadata":{"id":"TciKEp9DYO8J"},"source":["You can also customize the tool name and JSON args by passing them into the tool decorator."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"GyV8pCp8YO8K","executionInfo":{"status":"ok","timestamp":1727727701644,"user_tz":-180,"elapsed":366,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["class SearchInput(BaseModel):\n","    query: str = Field(description=\"should be a search query\")\n","\n","@tool(\"search-tool\", args_schema=SearchInput, return_direct=True)\n","def search(query: str) -> str:\n","    \"\"\"Look up things online.\"\"\"\n","    return \"LangChain\""]},{"cell_type":"markdown","metadata":{"id":"XO27FSXxYO8K"},"source":["## StructuredTool dataclass"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"6D1vGMuiYO8K","executionInfo":{"status":"ok","timestamp":1727727748426,"user_tz":-180,"elapsed":862,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["def search_function(query: str):\n","    return \"LangChain\"\n","\n","search = StructuredTool.from_function(\n","    func=search_function,\n","    name=\"Search\",\n","    description=\"useful for when you need to answer questions about current events\",\n","    # coroutine= ... <- you can specify an async method if desired as well\n",")"]},{"cell_type":"markdown","metadata":{"id":"DuWf0TMpYO8K"},"source":["--------"]},{"cell_type":"markdown","metadata":{"id":"TLIPAEKEYO8K"},"source":["## [Agents](https://python.langchain.com/docs/modules/agents/)\n","\n","The core idea of agents is to use a language model to choose a sequence of actions to take. In chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a reasoning engine to determine which actions to take and in which order.\n","\n","There are lots of different [types of agents](https://python.langchain.com/docs/modules/agents/agent_types/) that LangChain offer."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"A1Txy4AVYO8K","executionInfo":{"status":"ok","timestamp":1727727875033,"user_tz":-180,"elapsed":820,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["from langchain.agents import tool\n","\n","# 1. Create the tool:\n","@tool\n","def get_word_length(word: str) -> int:\n","    \"\"\"Returns the length of a word.\"\"\"\n","    return len(word)\n","\n","# 2. Assign the tools to a Python list:\n","tools = [get_word_length]"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"CTQj9xsmYO8K","executionInfo":{"status":"ok","timestamp":1727727992703,"user_tz":-180,"elapsed":368,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["# 3. Create the ChatPromptTemplate:\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are very powerful assistant, but don't know current events\",\n","        ),\n","        (\"user\", \"{input}\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ]\n",")"]},{"cell_type":"markdown","metadata":{"id":"IviSv7bbYO8K"},"source":["## Bind tools to LLM\n","\n","How does the agent know what tools it can use?\n","\n","In this case we’re relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"eMIX8eJcYO8K","executionInfo":{"status":"ok","timestamp":1727728025948,"user_tz":-180,"elapsed":1969,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","# 4. Create the LLM and bind the tools directly to the LLM:\n","llm = ChatOpenAI(model='gpt-4-turbo')\n","llm_with_tools = llm.bind_tools(tools=tools)"]},{"cell_type":"markdown","metadata":{"id":"PO9WAn4tYO8K"},"source":["## Create the Agent\n","\n","Putting those pieces together, we can now create the agent. We will import two last utility functions: a component for formatting intermediate steps (agent action, tool output pairs) to input messages that can be sent to the model, and a component for converting the output message into an agent action/agent finish."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"_fDzZAt8YO8K","executionInfo":{"status":"ok","timestamp":1727728058771,"user_tz":-180,"elapsed":441,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["from langchain.agents.format_scratchpad.openai_tools import (\n","    format_to_openai_tool_messages,\n",")\n","from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n","\n","# 5. Creating the LCEL agent chain:\n","agent = (\n","    {\n","        \"input\": lambda x: x[\"input\"],\n","        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n","            x[\"intermediate_steps\"]\n","        ),\n","    }\n","    | prompt\n","    | llm_with_tools\n","    | OpenAIToolsAgentOutputParser()\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"EHosKIGaYO8K","executionInfo":{"status":"ok","timestamp":1727728165461,"user_tz":-180,"elapsed":448,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["from langchain.agents import AgentExecutor\n","\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"-XxEJQ0yYO8K","outputId":"bf0fbad3-8894-448a-e808-7a9b0cbd0643","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727728173832,"user_tz":-180,"elapsed":2236,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new None chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `get_word_length` with `{'word': 'data'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m4\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"data\" has 4 letters.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'actions': [ToolAgentAction(tool='get_word_length', tool_input={'word': 'data'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'data'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8noEjbmFYQsySpCAC9zvqq3e', 'function': {'arguments': '{\"word\":\"data\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_82bed303cf'}, id='run-c9378b3d-36f3-4ae7-b997-68c745bcf7d8', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'data'}, 'id': 'call_8noEjbmFYQsySpCAC9zvqq3e', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"data\"}', 'id': 'call_8noEjbmFYQsySpCAC9zvqq3e', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_8noEjbmFYQsySpCAC9zvqq3e')],\n","  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8noEjbmFYQsySpCAC9zvqq3e', 'function': {'arguments': '{\"word\":\"data\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_82bed303cf'}, id='run-c9378b3d-36f3-4ae7-b997-68c745bcf7d8', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'data'}, 'id': 'call_8noEjbmFYQsySpCAC9zvqq3e', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"data\"}', 'id': 'call_8noEjbmFYQsySpCAC9zvqq3e', 'index': 0, 'type': 'tool_call_chunk'}])]},\n"," {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_length', tool_input={'word': 'data'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'data'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8noEjbmFYQsySpCAC9zvqq3e', 'function': {'arguments': '{\"word\":\"data\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_82bed303cf'}, id='run-c9378b3d-36f3-4ae7-b997-68c745bcf7d8', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'data'}, 'id': 'call_8noEjbmFYQsySpCAC9zvqq3e', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"data\"}', 'id': 'call_8noEjbmFYQsySpCAC9zvqq3e', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_8noEjbmFYQsySpCAC9zvqq3e'), observation=4)],\n","  'messages': [FunctionMessage(content='4', additional_kwargs={}, response_metadata={}, name='get_word_length')]},\n"," {'output': 'The word \"data\" has 4 letters.',\n","  'messages': [AIMessage(content='The word \"data\" has 4 letters.', additional_kwargs={}, response_metadata={})]}]"]},"metadata":{},"execution_count":14}],"source":["list(agent_executor.stream( {\"input\": \"How many letters in the word data\"}))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"z8tEfHO3YO8L","outputId":"f51acaf5-5028-4582-918f-da4389eed24b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727728196889,"user_tz":-180,"elapsed":2754,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `get_word_length` with `{'word': 'data'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m4\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"data\" has 4 letters.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'How many letters in the word data',\n"," 'output': 'The word \"data\" has 4 letters.'}"]},"metadata":{},"execution_count":15}],"source":["agent_executor.invoke({\"input\": \"How many letters in the word data\"})"]},{"cell_type":"markdown","metadata":{"id":"0-LPbQD9YO8L"},"source":["## Adding in Memory\n","\n","This is great - we have an agent! However, this agent is stateless - it doesn’t remember anything about previous interactions. This means you can’t ask follow up questions easily. Let’s fix that by adding in memory.\n","\n","In order to do this, we need to do two things:\n","\n","Add a place for memory variables to go in the prompt\n","Keep track of the chat history\n","First, let’s add a place for memory in the prompt. We do this by adding a placeholder for messages with the key \"chat_history\". Notice that we put this ABOVE the new user input (to follow the conversation flow)."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"oWuAWtEPYO8L","executionInfo":{"status":"ok","timestamp":1727728234209,"user_tz":-180,"elapsed":1270,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["from langchain_core.prompts import MessagesPlaceholder\n","\n","MEMORY_KEY = \"chat_history\"\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n","        ),\n","        MessagesPlaceholder(variable_name=MEMORY_KEY),\n","        (\"user\", \"{input}\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ]\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"PVMVk4MBYO8L","executionInfo":{"status":"ok","timestamp":1727728258474,"user_tz":-180,"elapsed":333,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["from langchain_core.messages import AIMessage, HumanMessage\n","\n","chat_history = []"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"IVrDvHJZYO8L","executionInfo":{"status":"ok","timestamp":1727728265836,"user_tz":-180,"elapsed":1002,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["agent = (\n","    {\n","        \"input\": lambda x: x[\"input\"],\n","        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n","            x[\"intermediate_steps\"]\n","        ),\n","        \"chat_history\": lambda x: x[\"chat_history\"],\n","    }\n","    | prompt\n","    | llm_with_tools\n","    | OpenAIToolsAgentOutputParser()\n",")\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"oDtxXKIIYO8L","outputId":"db8e925f-e0de-4977-86e5-d4d47504bf48","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727728296404,"user_tz":-180,"elapsed":4248,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `get_word_length` with `{'word': 'data'}`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m4\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"data\" has 4 letters.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mYes, \"data\" is a real word. It refers to facts or information used usually to calculate, analyze, or plan something. It is commonly used in contexts involving research, statistics, and computing.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'is that a real word?',\n"," 'chat_history': [HumanMessage(content='how many letters in the word data?', additional_kwargs={}, response_metadata={}),\n","  AIMessage(content='The word \"data\" has 4 letters.', additional_kwargs={}, response_metadata={})],\n"," 'output': 'Yes, \"data\" is a real word. It refers to facts or information used usually to calculate, analyze, or plan something. It is commonly used in contexts involving research, statistics, and computing.'}"]},"metadata":{},"execution_count":19}],"source":["input1 = \"how many letters in the word data?\"\n","result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n","chat_history.extend(\n","    [\n","        HumanMessage(content=input1),\n","        AIMessage(content=result[\"output\"]),\n","    ]\n",")\n","agent_executor.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})"]},{"cell_type":"markdown","metadata":{"id":"Z0buHZSqYO8L"},"source":["## Customizing the memory by wrapping it with a `specific session_id`:"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"3Gc-YF8xYO8L","executionInfo":{"status":"ok","timestamp":1727728345676,"user_tz":-180,"elapsed":503,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[],"source":["# Customising the memory by\n","from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain_core.chat_history import BaseChatMessageHistory\n","from langchain_core.runnables.history import RunnableWithMessageHistory\n","\n","store = {}\n","\n","from langchain.agents.format_scratchpad.openai_tools import (\n","    format_to_openai_tool_messages,\n",")\n","from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n","\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n","        ),\n","        MessagesPlaceholder(variable_name='history'),\n","        (\"user\", \"{input}\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ]\n",")\n","\n","agent = (\n","    {\n","        \"input\": lambda x: x[\"input\"],\n","        \"history\": lambda x: x.get(\"history\", []),\n","        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n","            x[\"intermediate_steps\"]\n","        ),\n","    }\n","    | prompt\n","    | llm_with_tools\n","    | OpenAIToolsAgentOutputParser()\n",")\n","\n","agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n","\n","def get_session_history(session_id: str) -> BaseChatMessageHistory:\n","    if session_id not in store:\n","        store[session_id] = ChatMessageHistory()\n","    return store[session_id]\n","\n","\n","with_message_history = RunnableWithMessageHistory(\n","    agent_executor,\n","    get_session_history,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"history\",\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"rTpQfXjRYO8L","outputId":"f918f671-58fb-4219-fe84-6b831e9aa14e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727728429591,"user_tz":-180,"elapsed":1530,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mHello, James! How can I assist you today?\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'My name is James',\n"," 'history': [],\n"," 'output': 'Hello, James! How can I assist you today?'}"]},"metadata":{},"execution_count":21}],"source":["with_message_history.invoke(\n","    {\"input\": \"My name is James\", \"history\": []},\n","    config={\"configurable\": {\"session_id\": \"some_session_id\"}},\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"9v6pqguDYO8L","outputId":"d3c26f3e-42be-4692-b701-df03d5ba31e4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727728443104,"user_tz":-180,"elapsed":934,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mYour name is James. How can I help you further?\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'What is my name?',\n"," 'history': [HumanMessage(content='My name is James', additional_kwargs={}, response_metadata={}),\n","  AIMessage(content='Hello, James! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n"," 'output': 'Your name is James. How can I help you further?'}"]},"metadata":{},"execution_count":22}],"source":["with_message_history.invoke(\n","    {\"input\": \"What is my name?\"},\n","    config={\"configurable\": {\"session_id\": \"some_session_id\"}},\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"PVAGlim2YO8M","outputId":"d769511c-0127-4218-dabc-ce6805ead4e9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727728469301,"user_tz":-180,"elapsed":1593,"user":{"displayName":"Kempsly Silencieux","userId":"00710149443443216664"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mYou haven't mentioned your name yet. Could you please tell me your name?\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'What is my name?',\n"," 'history': [HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}),\n","  AIMessage(content=\"You haven't mentioned your name yet. Could you please tell me your name?\", additional_kwargs={}, response_metadata={})],\n"," 'output': \"You haven't mentioned your name yet. Could you please tell me your name?\"}"]},"metadata":{},"execution_count":24}],"source":["with_message_history.invoke(\n","    {\"input\": \"What is my name?\"},\n","    config={\"configurable\": {\"session_id\": \"some_different_session_id\"}},\n",")"]},{"cell_type":"code","source":[],"metadata":{"id":"W2CVPn_DpD2c"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}